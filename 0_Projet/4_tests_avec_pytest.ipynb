{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester avec [pytest](https://docs.pytest.org/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copier ce fichier dans votre espace personnel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir utiliser `pytest` à l'intérieur d'un notebook (exécuter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Utiliser la table des matières pour ouvrir/fermer chaque section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Pourquoi écrire des tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "* Qui a envie de faire des **tests à la main** (print, suite d'interactions...) lorsque ça va mal?\n",
    "* Lorsque vous venez à bout d'un bogue -*bug*-, les tests sont une façon de s'assurer que vous n'en avez pas introduit d'autres par la même occasion\n",
    "* Si vous avez des **prérequis clairs**, vous pouvez vérifier qu'ils sont bien respectés en réalisant **un test pour chacun d'eux**\n",
    "* Vous n'aurez pas peur au moment de la réorganisation du code -**refactoring**-\n",
    "* Les tests *documentent l'organisation* de votre code - ils montrent aux autres codeurs des cas d'utilisation -*use case*- de votre implémentation\n",
    "* Cette liste est sans fin..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### [Développement dirigé par les tests - Test-driven development](https://en.wikipedia.org/wiki/Test-driven_development) aka TDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "En bref, l'idée de base du TDD - développement dirigé par les tests - est d'**écrire les tests avant même de réaliser l'implémentation effective**.\n",
    "\n",
    "Le bénéfice le plus important, probablement, c'est que le développeur porte toute son attention à écrire des tests qui exprime ce que le programme est censé faire.\n",
    "\n",
    "Lorsqu'on procède dans l'autre sens - tests écris après l'implémentation - il y a de fortes chances qu'ils ne soient qu'une paraphrase de la logique déjà utilisée (et probablement mal ficelée) pour l'implémentation actuelle.\n",
    "\n",
    "Les tests sont «des citoyens de première classe» dans le **développement moderne et agile d'applications**, voila pourquoi il est si important de commencer à **penser TDD** pendant votre apprentissage de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "La manière de travailler du TDD peut se résumer comme suit:\n",
    "1. **Ajouter un scénario de test(s)** (*test case*) pour chaque modification / nouvelle fonctionnalité / résolution de bug que vous vous apprêter à entreprendre,\n",
    "2. Faire tourner tous les tests et vérifier que *le nouveau* **échoue**,\n",
    "3. **Implémenter** les changements requis,\n",
    "4. Faire de nouveau *tourner tous les tests* et vérifier que tout se passe bien (y compris le ou les nouveaux)\n",
    "5. **Réorganiser** le code (*refactoring*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Scénario de test avec `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "Supposons disposer d'une fonction nommée `somme_de_trois_nombres` pour laquelle nous souhaitons réaliser un test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cela pourrait être, par exemple, dans un fichier implementation.py\n",
    "def somme_de_trois_nombres(nb1, nb2, nb3):\n",
    "    return nb1 + nb2 + nb3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scénarios de test de `pytest` sont en réalité très similaires à ce que vous avez déjà vu dans les exercices.\n",
    "La plupart des exercices sont structurés comme des scénarios de test en divisant chaque exercice en trois cellules:\n",
    "1. Définition des variables à utiliser dans les tests,\n",
    "2. Votre implémentation (À ton tour!),\n",
    "3. Vérification que votre implémentation respecte l'énoncé en utilisant des assertions (`assert <test>`).\n",
    "\n",
    "Voir l'exemple de scénario de test ci-dessous pour observer les similitudes entre l'organisation des exercices et la structure habituel des scénarios de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "# Mention spéciale pour un notebook \n",
    "# à utiliser au tout début de la cellule qui contient un ou plusieurs tests.\n",
    "# C'est seulement requis pour faire fonctionner pytest dans les notebooks Jupyter.\n",
    "\n",
    "# Cela pourrait se situer dans un fichier test_implementation.py\n",
    "def test_somme_de_trois_nombres():\n",
    "    # 1. Définir les variables utilisées dans le test\n",
    "    nb1 = 2\n",
    "    nb2 = 3\n",
    "    nb3 = 5\n",
    "    \n",
    "    # 2. Appeler la fonction à tester\n",
    "    resultat = somme_de_trois_nombres(nb1, nb2, nb3)\n",
    "    \n",
    "    # 3. Vérifier que cela produit le résultat voulu\n",
    "    assert resultat == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant changer la ligne `assert resultat == 10` de façon à faire échouer l'assertion afin de voir à quoi ressemble un test qui échoue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un test donné peut bien sûr contenir plusieurs assertions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice - Créer votre premier scénario de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'implémentation de la fonction `obtenir_les_multiples_de_cinq`. Votre mission est de créer un scénario de test pour vérifier que cette fonction fait bien ce qu'elle est censée faire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "def obtenir_les_multiples_de_cinq(nombres):\n",
    "    '''Retourne la liste des nombres qui sont divisibles par cinq dans la liste fournie en argument'''\n",
    "    resultat = []\n",
    "    for nb in nombres:\n",
    "        if not nb % 5:\n",
    "            resultat.append(nb)\n",
    "\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_obtenir_les_multiples_de_cinq():\n",
    "    # Votre implémentation ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_obtenir_les_multiples_de_cinq():\n",
    "    # 1. Définir variables ...\n",
    "    nbs1 = [0, 5, 10, 15]\n",
    "    nbs2 = [2, 15, -28, -10125]\n",
    "    \n",
    "    # 2. Appeler la fonction\n",
    "    res0 = obtenir_les_multiples_de_cinqs([])\n",
    "    res1 = obtenir_les_multiples_de_cinq(nbs1)\n",
    "    res2 = obtenir_les_multiples_de_cinq(nbs2)\n",
    "    \n",
    "    # 3. quelques assertions\n",
    "    assert res0 = []\n",
    "    assert res1 == nbs1\n",
    "    assert res2 == [nbs2[1], nbs2[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réutilisation - [`@pytest.fixture`](https://docs.pytest.org/en/latest/fixture.html#pytest-fixtures-explicit-modular-scalable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposons disposer de l'implémentation d'une classe `Personne` que nous souhaitons tester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cela pourrait se trouver dans un fichier personne.py par exemple\n",
    "class Personne:\n",
    "    def __init__(self, prenom, nom, age):\n",
    "        self.prenom = prenom\n",
    "        self.nom = nom\n",
    "        self.age = age\n",
    "    \n",
    "    @property\n",
    "    def nom_complet(self):\n",
    "        return f'{self.prenom} {self.nom}'\n",
    "    \n",
    "    @property\n",
    "    def comme_dictionnaire(self):\n",
    "        return {'nom': self.nom_complet, 'age': self.age}\n",
    "        \n",
    "    def augmenter_age(self, annees):\n",
    "        if annees < 0:\n",
    "            raise ValueError('Je ne peux pas rajeunir les gens :(')\n",
    "        self.age += annees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez facilement **réutiliser du code de test** en utilisant les «**fixtures**» de pytest.\n",
    "\n",
    "Si vous placez vos fixtures dans un fichier [_conftest.py_](https://docs.pytest.org/en/latest/fixture.html#conftest-py-sharing-fixture-functions), elles seront disponibles pour tous vos scénarios de test.\n",
    "\n",
    "En général, le fichier _conftest.py_ se situe à la racine d'un répertoire _tests_, qui comme son nom l'indique va grouper tous vos fichiers de tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cela serait soit dans conftest.py soit dans test_personne.py\n",
    "@pytest.fixture()\n",
    "def personne_par_defaut():\n",
    "    personne = Personne(prenom='John', nom='Doe', age=82)\n",
    "    return personne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dès lors, vous pouvez utiliser la fixture `personne_par_defaut` dans les scénarios de tests effectifs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "# Cela se trouverait dans le fichier test_personne.py\n",
    "def test_nom_complet(personne_par_defaut): # Note: nous utilisons la fixture comme un argument du test\n",
    "    resultat = personne_par_defaut.nom_complet\n",
    "    assert resultat == 'John Doe'\n",
    "    \n",
    "    \n",
    "def test_comme_dictionnaire(personne_par_defaut):\n",
    "    attendu = {'nom': 'John Doe', 'age': 82}\n",
    "    resultat = personne_par_defaut.comme_dictionnaire\n",
    "    assert resultat == attendu\n",
    "    \n",
    "    \n",
    "def test_augmenter_age(personne_par_defaut):\n",
    "    personne_par_defaut.augmenter_age(1)\n",
    "    assert personne_par_defaut.age == 83\n",
    "    \n",
    "    personne_par_defaut.augmenter_age(10)\n",
    "    assert personne_par_defaut.age == 93\n",
    "    \n",
    "    \n",
    "def test_augmenter_age_avec_nombre_negatif(personne_par_defaut):\n",
    "    with pytest.raises(ValueError):\n",
    "        personne_par_defaut.augmenter_age(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant une fixture, nous pouvons utiliser la même `personne_par_defaut` pour tout nos scénarios de test!\n",
    "\n",
    "Dans le `test_augmenter_age_avec_nombre_negatif` nous avons utilisé [`pytest.raises`](https://docs.pytest.org/en/latest/assert.html#assertions-about-expected-exceptions) pour vérifier qu'une exception a bien été levée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice - Finaliser des scénarios de tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie test de l'implémentation de `ListeTaches` est incomplète. Compléter les portions `____` des tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "class TacheNonTrouvee(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ListeTaches:\n",
    "    def __init__(self):\n",
    "        self._tache = {}\n",
    "        self._fait = {}\n",
    "        self._compteur_tache = 1\n",
    "\n",
    "    @property\n",
    "    def taches(self):\n",
    "        return self._tache\n",
    "\n",
    "    @property\n",
    "    def taches_faites(self):\n",
    "        return self._fait\n",
    "\n",
    "    def ajouter(self, tache):\n",
    "        self._tache[self._compteur_tache] = tache\n",
    "        self._compteur_tache += 1\n",
    "\n",
    "    def achever(self, nombre):\n",
    "        if nombre not in self._tache:\n",
    "            raise TacheNonTrouvee(f\"{nombre} n'est pas dans la liste\")\n",
    "\n",
    "        tache = self._tache.pop(nombre)\n",
    "        self._fait[nombre] = tache\n",
    "\n",
    "    def supprimer(self, nombre):\n",
    "        if nombre not in self._tache:\n",
    "            raise TacheNonTrouvee(f\"{nombre} n'est pas dans la liste\")\n",
    "\n",
    "        del self._tache[nombre]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaliser les tests pour `ListeTaches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "\n",
    "@pytest.____\n",
    "def liste_taches():\n",
    "    lt = ListeTaches()\n",
    "    lt.ajouter('acheter du lait')\n",
    "    lt.ajouter('sortir le chien')\n",
    "    lt.ajouter('apprendre les fixtures de pytest')\n",
    "    ____ ____\n",
    "\n",
    "\n",
    "def test_taches_property(liste_taches):\n",
    "    a_faire = liste_taches.taches\n",
    "    assert a_faire == {\n",
    "        1: 'acheter du lait',\n",
    "        2: 'sortir le chien',\n",
    "        3: 'apprendre les fixtures de pytest'\n",
    "    }\n",
    "\n",
    "\n",
    "def test_ajouter(____):\n",
    "    liste_taches.ajouter('Vérifier dans la doc de pytest')\n",
    "    a_faire = liste_taches.taches\n",
    "    assert a_faire[4] == ____\n",
    "\n",
    "\n",
    "def test_achever(liste_taches):\n",
    "    # S'assurer qu'aucune tache n'a encore été faite\n",
    "    assert not liste_taches.taches_faites\n",
    "\n",
    "    liste_taches.achever(3)\n",
    "    fait = liste_taches.____\n",
    "    a_faire = liste_taches.____\n",
    "    assert fait[3] == 'apprendre les fixtures de pytest'\n",
    "    assert 3 not in ____\n",
    "\n",
    "\n",
    "def test_achever_avec_no_tache_inconnu(liste_taches):\n",
    "    # Voila comment tester qu'une certaine exception est bien levée\n",
    "    with pytest.raises(TacheNonTrouvee):\n",
    "        liste_taches.achever(10)\n",
    "\n",
    "\n",
    "def test_supprimer(liste_taches):\n",
    "    liste_taches.supprimer(1)\n",
    "    fait = liste_taches.taches_faites\n",
    "    a_faire = liste_taches.taches\n",
    "\n",
    "    assert 1 not in ____\n",
    "    # S'assurer que la tache n'a pas été mise dans fait\n",
    "    ____ not fait\n",
    "\n",
    "\n",
    "def test_supprimer_avec_no_tache_inconnu(liste_taches):\n",
    "    with pytest.____(____):\n",
    "        liste_taches.supprimer(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def liste_taches():\n",
    "    lt = ListeTaches()\n",
    "    lt.ajouter('acheter du lait')\n",
    "    lt.ajouter('sortir le chien')\n",
    "    lt.ajouter('apprendre les fixtures de pytest')\n",
    "    return lt\n",
    "\n",
    "\n",
    "def test_taches_property(liste_taches):\n",
    "    a_faire = liste_taches.taches\n",
    "    assert a_faire == {\n",
    "        1: 'acheter du lait',\n",
    "        2: 'sortir le chien',\n",
    "        3: 'apprendre les fixtures de pytest',\n",
    "    }\n",
    "\n",
    "\n",
    "def test_ajouter(liste_taches):\n",
    "    liste_taches.ajouter('Vérifier dans la doc de pytest')\n",
    "    a_faire = liste_taches.taches\n",
    "    assert a_faire[4] == 'Vérifier dans la doc de pytest'\n",
    "\n",
    "\n",
    "def test_achever(liste_taches):\n",
    "    # S'assurer qu'aucune tache n'a encore été faite\n",
    "    assert not liste_taches.taches_faites\n",
    "\n",
    "    liste_taches.achever(3)\n",
    "    fait = liste_taches.taches_faites\n",
    "    a_faire = liste_taches.taches\n",
    "    assert fait[3] == 'apprendre les fixtures de pytest'\n",
    "    assert 3 not in a_faire\n",
    "\n",
    "\n",
    "def test_achever_avec_no_tache_inconnu(liste_taches):\n",
    "    # Voila comment tester qu'une certaine exception est bien levée\n",
    "    with pytest.raises(TacheNonTrouvee):\n",
    "        liste_taches.achever(10)\n",
    "\n",
    "\n",
    "def test_supprimer(liste_taches):\n",
    "    liste_taches.supprimer(1)\n",
    "    fait = liste_taches.taches_faites\n",
    "    a_faire = liste_taches.taches\n",
    "\n",
    "    assert 1 not in a_faire\n",
    "    # S'assurer que la tache n'a pas été mise dans fait\n",
    "    assert 1 not in fait\n",
    "\n",
    "\n",
    "def test_supprimer_avec_no_tache_inconnu(liste_taches):\n",
    "    with pytest.raises(TacheNonTrouvee):\n",
    "        liste_taches.supprimer(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Factorisation - [`@pytest.mark.parametrize`](https://docs.pytest.org/en/latest/parametrize.html#pytest-mark-parametrize-parametrizing-test-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfois vous voulez tester la même fonctionnalité avec de **multiples entrées**. \n",
    "\n",
    "`pytest.mark.parametrize` est votre solution pour définir de multiples entrées avec les sorties attendues. \n",
    "\n",
    "Considérons l'implémentation suivante de la fonction `remplacer_noms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par exemple dans string_manipulate.py\n",
    "def remplacer_noms(chaine_originale, nouveau_nom):\n",
    "    \"\"\"Remplace les noms (qui débutent par une majuscule) de la chaine_originale par nouveau_nom\"\"\"\n",
    "    mots = chaine_originale.split()\n",
    "    mots_manipulees = [nouveau_nom if mot.istitle() else mot for mot in mots]\n",
    "    return ' '.join(mots_manipulees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons tester cette fonction avec plusieurs entrées en utilisant l'annotation:\n",
    "\n",
    "```python\n",
    "@pytest.mark.parametrize(\"par1, par2, res_attendu\", [(v1, v2, v3), (ov1, ov2, ov3), ...])\n",
    "def test_fn(par1, par2, res_attendu):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Voici un exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "# Cela pourrait être dans votre module de test\n",
    "@pytest.mark.parametrize(\"orig, nom, attendu\", [\n",
    "        ('je suis Lisa', 'John Doe', 'je suis John Doe'),\n",
    "        ('comment vont Anne et Bob', 'John', 'comment vont John et John'),\n",
    "        ('pas de nom ici', 'John Doe', 'pas de nom ici'),\n",
    "    ])\n",
    "def test_remplacer_noms(orig, nom, attendu):\n",
    "    resultat = remplacer_noms(orig, nom)\n",
    "    assert resultat == attendu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice - Tester les [nombres de Fibonacci](https://en.wikipedia.org/wiki/Fibonacci_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémenter un test pour la fonction `fibonacci`. Utiliser `pytest.mark.parametrize` et tester au moins avec les nombres: 0, 1, 2, 3, et 10. Vous pouvez trouver les résultats attendus et plus d'informations à propos des suites de Fibonacci [ici](https://en.wikipedia.org/wiki/Fibonacci_number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "def fibonacci(nombre):\n",
    "    if nombre in [0, 1]:\n",
    "        return nombre\n",
    "    return fibonacci(nombre - 1) + fibonacci(nombre - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "# À vous de jouer!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "@pytest.mark.parametrize(\"nb,attendu\",[(0,0),(1,1),(2,1),(3,2),(10,55)])\n",
    "def test_fibonacci(nb, attendu):\n",
    "    resultat = fibonacci(nb)\n",
    "    assert resultat == attendu\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
